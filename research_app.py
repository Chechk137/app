import streamlit as st
import requests
import datetime
import random
import time
import json
import os

# --- 1. ì„¤ì • ë° ìƒìˆ˜ ---

MISSIONS = [
    {"id": 1, "text": "Top Tier ì €ë„(Nature, Science ë“±) ë…¼ë¬¸ 1í¸ ìˆ˜ì§‘", "type": "journal", "target": "top_tier", "count": 1, "reward": 150},
    {"id": 2, "text": "5ì¸ ì´ìƒ í˜‘ì—… ì—°êµ¬(Team Science) ìˆ˜ì§‘", "type": "team", "target": 5, "count": 1, "reward": 100},
    {"id": 3, "text": "í•¨ì • ë…¼ë¬¸(ì°¸ê³ ë¬¸í—Œ ë¶€ì¡± ë“±) í”¼í•˜ê¸°", "type": "avoid_trap", "target": "trap", "count": 0, "reward": 0},
    {"id": 4, "text": "ì—°êµ¬ ì ìˆ˜ 1500ì  ë‹¬ì„±í•˜ê¸°", "type": "score", "target": 1500, "count": 1500, "reward": 500},
]

DATA_DIR = "user_data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# --- 2. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜ ---

def load_user_data(user_id):
    file_path = os.path.join(DATA_DIR, f"{user_id}.json")
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return {"score": 0, "inventory": [], "mission_id": 1}

def save_user_data(user_id):
    file_path = os.path.join(DATA_DIR, f"{user_id}.json")
    data = {
        "score": st.session_state.score,
        "inventory": st.session_state.inventory,
        "mission_id": st.session_state.mission_id
    }
    try:
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- 3. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ---

def get_current_year():
    return datetime.datetime.now().year

def evaluate_paper(paper_data):
    current_year = get_current_year()
    year = paper_data.get('year', current_year - 5)
    age = current_year - year
    title_lower = paper_data['title'].lower()
    citation_count = paper_data.get('citations', 0)
    
    evidence_keywords = [
        'in vivo', 'in vitro', 'randomized', 'efficacy', 'mechanism', 'signaling', 
        'experiment', 'analysis', 'clinical', 'activity', 'synthesis', 'design', 
        'evaluation', 'characterization', 'properties', 'performance', 'application'
    ]
    has_evidence = any(k in title_lower for k in evidence_keywords)
    
    top_journals = ['nature', 'science', 'cell', 'lancet', 'nejm', 'jama', 'ieee', 'pnas', 'advanced materials', 'cancer discovery', 'chem', 'acs', 'angewandte']
    journal_lower = paper_data.get('journal', "").lower()
    is_top_tier = any(j in journal_lower for j in top_journals)

    author_count = paper_data.get('author_count', 1)
    is_big_team = author_count >= 5
    is_solo = author_count == 1

    ref_count = paper_data.get('ref_count') 
    
    integrity_status = "valid" 
    risk_reason = ""

    if ref_count is None:
        if citation_count < 5 and not is_top_tier:
            integrity_status = "uncertain"
            risk_reason = "ë©”íƒ€ë°ì´í„° ëˆ„ë½ (ì°¸ê³ ë¬¸í—Œ ì •ë³´ ì—†ìŒ)"
    elif ref_count < 5:
        if citation_count < 5 and not is_top_tier:
            integrity_status = "suspected"
            risk_reason = "ì°¸ê³ ë¬¸í—Œ ìˆ˜ ë¶€ì¡± (ë°ì´í„° ë¹ˆì•½ ì˜ì‹¬)"

    potential = 0
    potential_type = "normal"
    reasons = []

    # ì ìˆ˜ ì‚°ì • ë¡œì§
    if integrity_status == "suspected":
        potential = 0
        potential_type = "bad"
        reasons.append("ë°ì´í„° ì‹ ë¢°ë„ ë‚®ìŒ")
    elif age > 10 and citation_count < 5:
        potential = 0
        potential_type = "bad"
        reasons.append("ì˜¤ë˜ë˜ê³  ì¸ìš© ì—†ëŠ” ë„íƒœëœ ì—°êµ¬")
    elif citation_count < 50 and age <= 3:
        bonus = 0
        if has_evidence:
            bonus += 100
            reasons.append("ì‹¤í—˜ì  ê·¼ê±°(Evidence)")
        if is_top_tier:
            bonus += 150
            reasons.append("Top Tier ì €ë„")
        if is_big_team:
            bonus += 50
            reasons.append("ëŒ€ê·œëª¨ ì—°êµ¬íŒ€")
        
        if bonus >= 200:
            potential = 300 + bonus
            potential_type = "amazing"
            reasons.insert(0, "ìµœì‹  ëª…ì‘ ë°œê²¬!")
        elif bonus > 0:
            potential = 50 + bonus
            potential_type = "good"
        else:
            potential = 30
            potential_type = "normal"
            reasons.append("í‰ì´í•œ ìµœì‹  ì—°êµ¬")
    else:
        potential = 20
        if is_top_tier:
            potential += 50
            reasons.append("ê¶Œìœ„ ìˆëŠ” ì €ë„")
        if has_evidence:
            potential += 30
        potential_type = "good"
        reasons.append("ì´ë¯¸ ê²€ì¦ëœ ì•ˆì „í•œ ì—°êµ¬")

    if is_solo and not has_evidence and not is_top_tier:
        potential = max(0, potential - 20)
        reasons.append("ë‹¨ë… ì—°êµ¬(ë°ì´í„° ë¶€ì¡± ìœ„í—˜)")

    display_score = int(10 + (citation_count ** 0.5) * 2)
    total_estimated_value = potential + display_score
    ai_score = min(100, int((total_estimated_value / 400) * 100))

    reason_str = ", ".join(reasons) if reasons else "íŠ¹ì´ ì‚¬í•­ ì—†ìŒ"

    return {
        "display_score": display_score,
        "potential": potential,
        "potential_type": potential_type,
        "ai_score": ai_score,
        "reason": reason_str,
        "has_evidence": has_evidence,
        "is_top_tier": is_top_tier,
        "is_big_team": is_big_team,
        "integrity_status": integrity_status,
        "risk_reason": risk_reason
    }

def search_crossref_api(query):
    # ë”°ì˜´í‘œ ê²€ìƒ‰ ê°ì§€
    is_exact_mode = query.startswith('"') and query.endswith('"')
    clean_query = query.strip('"') if is_exact_mode else query
    
    try:
        url = f"https://api.crossref.org/works?query={clean_query}&rows=40&sort=relevance"
        response = requests.get(url, timeout=5)
        data = response.json()
    except Exception as e:
        st.error("API ì—°ê²° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return [], False

    if not data.get('message') or not data['message'].get('items'):
        return [], False

    items = data['message']['items']
    valid_papers = []
    current_year = get_current_year()

    for item in items:
        if not item.get('DOI'): continue
        if not item.get('title'): continue
        if not item.get('author'): continue
        
        title = item['title'][0]
        title_lower = title.lower()
        if len(title) < 5: continue
        
        invalid_titles = [
            "announcement", "editorial", "issue info", "table of contents", 
            "front matter", "back matter", "author index", "subject index", 
            "correction", "erratum", "publisher's note", "conference info",
            "trial number", "trial registration", "clinicaltrials.gov", "identifier",
            "&na;", "unknown", "calendar", "masthead", "abstracts", "session",
            "meeting", "symposium", "workshop", "chinese journal", "test", 
            "protocol", "data descriptor", "dataset"
        ]
        
        if any(inv in title_lower for inv in invalid_titles): continue
        if "&na;" in title_lower: continue

        authors_raw = item['author']
        valid_authors = []
        for a in authors_raw:
            given = a.get('given', '').strip()
            family = a.get('family', '').strip()
            full_name = f"{given} {family}".strip()
            if full_name and "&na;" not in full_name.lower() and "anonymous" not in full_name.lower():
                valid_authors.append(full_name)
        
        if not valid_authors: continue

        citations = item.get('is-referenced-by-count', 0)
        journal = item.get('container-title', ["Unknown Journal"])[0]
        ref_count = item.get('reference-count')
        
        pub_year = current_year - 5
        if item.get('published') and item['published'].get('date-parts'):
             pub_year = item['published']['date-parts'][0][0]
        elif item.get('created') and item['created'].get('date-parts'):
             pub_year = item['created']['date-parts'][0][0]

        paper_data_for_eval = {
            'title': title, 'year': pub_year, 'citations': citations, 
            'journal': journal, 'author_count': len(valid_authors), 'ref_count': ref_count
        }
        eval_result = evaluate_paper(paper_data_for_eval)

        paper_obj = {
            'id': item['DOI'],
            'title': title,
            'authors': valid_authors[:3], 
            'author_full_count': len(valid_authors),
            'journal': journal,
            'year': pub_year,
            'citations': citations,
            'ref_count': ref_count if ref_count is not None else 0,
            'url': f"https://doi.org/{item['DOI']}",
            **eval_result,
            'is_reviewed': False
        }
        valid_papers.append(paper_obj)
    
    if not is_exact_mode:
        valid_papers.sort(key=lambda x: x['ai_score'], reverse=True)
            
    return valid_papers[:12], is_exact_mode

# --- 3. Streamlit UI ---

st.set_page_config(page_title="Research Simulator", page_icon="ğŸ“", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'user_id' not in st.session_state:
    st.session_state['user_id'] = None
if 'score' not in st.session_state:
    st.session_state['score'] = 0
if 'inventory' not in st.session_state:
    st.session_state['inventory'] = []
if 'mission_id' not in st.session_state:
    st.session_state['mission_id'] = 1
if 'search_results' not in st.session_state:
    st.session_state['search_results'] = []

def get_level_info(score):
    level_threshold = 500
    level = (score // level_threshold) + 1
    progress = (score % level_threshold) / level_threshold
    next_milestone = (level) * level_threshold
    return level, progress, next_milestone

def check_mission(paper, action):
    current_m = next((m for m in MISSIONS if m['id'] == st.session_state.mission_id), None)
    if not current_m: return

    completed = False
    m_type = current_m['type']
    
    if m_type == "journal" and action == "collect" and paper['is_top_tier']:
        completed = True
    elif m_type == "team" and action == "collect" and paper['is_big_team']:
        completed = True
    elif m_type == "score" and st.session_state.score >= current_m['target']:
        completed = True
    
    if completed:
        st.session_state.score += current_m['reward']
        st.session_state.mission_id += 1
        st.toast(f"ğŸ‰ ë¯¸ì…˜ ì™„ë£Œ! ë³´ìƒ +{current_m['reward']}ì ", icon="ğŸ")
        # [ìˆ˜ì •] user_id ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ì €ì¥
        if st.session_state.get("user_id"):
            save_user_data(st.session_state.user_id)

with st.sidebar:
    st.title("ğŸ“ ì—°êµ¬ ì‹œë®¬ë ˆì´í„°")
    st.caption("Outlier Hunter Edition")
    
    # [ìˆ˜ì •] ì•ˆì „í•œ ì†ì„± ì ‘ê·¼ (.get ì‚¬ìš©)
    if not st.session_state.get("user_id"):
        st.markdown("### ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!")
        user_input = st.text_input("ì—°êµ¬ì ì´ë¦„ (ID)ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: Dr.Kim")
        if st.button("ë¡œê·¸ì¸ / ì‹œì‘í•˜ê¸°"):
            if user_input:
                st.session_state.user_id = user_input
                saved_data = load_user_data(user_input)
                st.session_state.score = saved_data["score"]
                st.session_state.inventory = saved_data["inventory"]
                st.session_state.mission_id = saved_data["mission_id"]
                st.success(f"{user_input}ë‹˜ìœ¼ë¡œ ë¡œê·¸ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
            else:
                st.warning("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    st.info(f"ğŸ‘¤ **{st.session_state.user_id}** ì—°êµ¬ì›")
    if st.button("ë¡œê·¸ì•„ì›ƒ (ì €ì¥ë¨)", use_container_width=True):
        save_user_data(st.session_state.user_id)
        st.session_state.user_id = None
        st.rerun()

    st.divider()
    
    current_level, progress, next_score = get_level_info(st.session_state.score)
    st.metric("ì—°êµ¬ ë ˆë²¨", f"Lv. {current_level}")
    st.write(f"í˜„ì¬ ì ìˆ˜: {st.session_state.score} / {next_score}")
    st.progress(progress)
    
    st.divider()
    st.metric("ë³´ìœ  ë…¼ë¬¸", f"{len(st.session_state.inventory)}í¸")
    
    current_mission = next((m for m in MISSIONS if m['id'] == st.session_state.mission_id), None)
    if current_mission:
        st.info(f"ğŸ¯ ë¯¸ì…˜: {current_mission['text']}")
    else:
        st.success("ğŸ† ëª¨ë“  ë¯¸ì…˜ ì™„ë£Œ!")

    st.divider()
    st.markdown("#### ğŸ“Š í‰ê°€ ê°€ì´ë“œ")
    st.markdown("""
    1. **ì¦ê±° ì í•©ì„± (Evidence)**
       : in vivo, efficacy ë“± ì‹¤í—˜ í‚¤ì›Œë“œ í¬í•¨
    2. **ì €ë„ ê¶Œìœ„ (Prestige)**
       : Nature, Science ë“± Top Tier ì €ë„
    3. **ì—°êµ¬ ê·œëª¨ (Collaboration)**
       : ì €ì 5ì¸ ì´ìƒ ì°¸ì—¬
    4. **ë°ì´í„° ì‹ ë¢°ë„ (Reliability)**
       : ì°¸ê³ ë¬¸í—Œ ìˆ˜ 10ê°œ ì´ìƒ (í•¨ì • ì£¼ì˜)
    5. **ì‹œì˜ì„±/ì¸ìš© (Opportunity)**
       : ìµœì‹ +ì €ì¸ìš©ì€ ê¸°íšŒ, ê³¼ê±°+ë¬´ì¸ìš©ì€ í•¨ì •
    """)  
    
    st.markdown("#### ğŸ“Š ê²€ìƒ‰ ë°©ë²•")
    st.markdown("""
    1. **ì¼ë°˜ ê²€ìƒ‰**
       : AI ì¶”ì²œ ì§€ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì¶”ì²œ
    2. **"[í‚¤ì›Œë“œ]"**
       : ë”°ì˜´í‘œ ê²€ìƒ‰ì„ í†µí•´ ì •í™•ë„ ìˆœìœ¼ë¡œ ê²€ìƒ‰
    """)



tab_search, tab_inventory = st.tabs(["ğŸ” ë…¼ë¬¸ ê²€ìƒ‰", "ğŸ“š ë‚´ ì„œì¬"])

with tab_search:
    col1, col2 = st.columns([4, 1])
    with col1:
        query = st.text_input("í‚¤ì›Œë“œ ì…ë ¥", placeholder='ì˜ˆ: "Immunotherapy" (ë”°ì˜´í‘œëŠ” ì •í™•ë„ìˆœ)')
    with col2:
        st.write("")
        st.write("")
        search_btn = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)

    if search_btn and query:
        with st.spinner("ë…¼ë¬¸ ë°ì´í„° ë¶„ì„ ì¤‘..."):
            results, is_exact = search_crossref_api(query)
            st.session_state.search_results = results
            st.session_state.is_exact_search = is_exact
            if not results:
                st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if st.session_state.search_results:
        count = len(st.session_state.search_results)
        sort_mode = "ì •í™•ë„(Relevance) ìˆœ" if st.session_state.is_exact_search else "AI ì¶”ì²œ(Potential) ìˆœ"
        st.caption(f"ê²€ìƒ‰ ê²°ê³¼ {count}ê±´ ({sort_mode})")
        
        for i, paper in enumerate(st.session_state.search_results):
            with st.container(border=True):
                c1, c2 = st.columns([5, 1.5])
                
                with c1:
                    st.progress(paper['ai_score'] / 100, text=f"AI ì¶”ì²œ ì§€ìˆ˜: {paper['ai_score']}ì ")
                    st.markdown(f"### {paper['title']}")
                    
                    tags = []
                    if paper['is_top_tier']: tags.append("ğŸ‘‘ Top Tier")
                    if paper['has_evidence']: tags.append("ğŸ”¬ Evidence")
                    if paper['is_big_team']: tags.append("ğŸ‘¥ Big Team")
                    if paper['integrity_status'] != "valid": tags.append("âš ï¸ ê²€ì¦ í•„ìš”")
                    
                    st.write(" ".join([f"`{t}`" for t in tags]))
                    
                    auth_display = ", ".join(paper['authors'])
                    if paper['author_full_count'] > 3:
                        auth_display += f" ì™¸ {paper['author_full_count'] - 3}ëª…"
                    
                    st.caption(f"{paper['year']} | {paper['journal']} | ì¸ìš© {paper['citations']}íšŒ | ì €ì: {auth_display}")
                    st.markdown(f"[ğŸ“„ ì›ë¬¸ ë³´ê¸°]({paper['url']})")

                with c2:
                    st.metric("ê¸°ë³¸ ë³´ìƒ", f"+{paper['display_score']}")
                    
                    is_owned = any(p['id'] == paper['id'] for p in st.session_state.inventory)
                    if is_owned:
                        st.button("ë³´ìœ ì¤‘", key=f"owned_{i}", disabled=True, use_container_width=True)
                    else:
                        if st.button("ìˆ˜ì§‘í•˜ê¸°", key=f"collect_{i}", type="secondary", use_container_width=True):
                            st.session_state.inventory.append(paper)
                            st.session_state.score += paper['display_score']
                            check_mission(paper, "collect")
                            save_user_data(st.session_state.user_id) 
                            st.rerun()

with tab_inventory:
    if not st.session_state.inventory:
        st.info("ìˆ˜ì§‘ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    cols = st.columns(2)
    for i, paper in enumerate(st.session_state.inventory):
        with cols[i % 2]:
            with st.container(border=True):
                status_emoji = "â“"
                status_text = "ë¯¸ê²€ì¦"
                if paper['is_reviewed']:
                    if paper['potential_type'] == "amazing": status_emoji, status_text = "âœ¨", "ëŒ€ì„±ê³µ"
                    elif paper['potential_type'] == "bad": status_emoji, status_text = "ğŸ’€", "ì‹¤íŒ¨"
                    elif paper['potential_type'] == "verified_user": status_emoji, status_text = "ğŸ›¡ï¸", "ì‚¬ìš©ì ìŠ¹ì¸"
                    else: status_emoji, status_text = "âœ…", "ê²€ì¦ë¨"

                st.markdown(f"**{paper['title']}**")
                st.caption(f"{status_emoji} {status_text} | {paper['journal']}")
                
                c_btn1, c_btn2 = st.columns([2, 1])
                with c_btn1:
                    if not paper['is_reviewed']:
                        if paper['integrity_status'] == "valid":
                            if st.button("ğŸ”¬ ì‹¬ì¸µ ê²€ì¦", key=f"rev_{i}", type="primary", use_container_width=True):
                                st.session_state.inventory[i]['is_reviewed'] = True
                                bonus = paper['potential']
                                st.session_state.score += bonus
                                st.session_state.inventory[i]['final_score'] = paper['display_score'] + bonus
                                
                                if paper['potential_type'] == 'amazing':
                                    st.toast("ëŒ€ë°•! ìˆ¨ê²¨ì§„ ëª…ì‘ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!", icon="ğŸ‰")
                                else:
                                    st.toast("ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="âœ…")
                                save_user_data(st.session_state.user_id) 
                                st.rerun()
                        else:
                            st.warning(paper['risk_reason'])
                            if st.button("ê°•ì œ ìŠ¹ì¸", key=f"force_{i}", use_container_width=True):
                                st.session_state.inventory[i]['is_reviewed'] = True
                                bonus = paper['potential']
                                st.session_state.score += bonus
                                st.session_state.inventory[i]['final_score'] = paper['display_score'] + bonus
                                st.session_state.inventory[i]['potential_type'] = "verified_user"
                                st.session_state.inventory[i]['reason'] = "ì‚¬ìš©ì ì§ì ‘ í™•ì¸ìœ¼ë¡œ ê²€ì¦ë¨"
                                save_user_data(st.session_state.user_id) 
                                st.rerun()
                    else:
                        st.success(f"íšë“: {paper.get('final_score', 0)}ì ")

                with c_btn2:
                    if st.button("ì‚­ì œ", key=f"del_{i}", use_container_width=True):
                        deduction = paper.get('final_score', paper['display_score'])
                        st.session_state.score = max(0, st.session_state.score - deduction)
                        st.session_state.inventory.pop(i)
                        st.toast(f"ë…¼ë¬¸ ì‚­ì œ. {deduction}ì  ì°¨ê°ë¨", icon="ğŸ—‘ï¸")
                        save_user_data(st.session_state.user_id) 
                        st.rerun()
                
                st.markdown(f"[ğŸ“„ ì›ë¬¸ ë³´ê¸°]({paper['url']})")
                
                if paper['is_reviewed']:
                    st.info(f"ë¶„ì„ ê²°ê³¼: {paper['reason']}")
